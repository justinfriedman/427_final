negative	I did not like this homework I thought it was hard to learn how to use the file command and I had a hard time getting it to work I hated having to do the mapreduce and use the toolrunner I do not understand what the toolrunner is or why we need to use it I would like this much better if I got more explanation or clear demos how to do it
negative	This was my least favorite homework I thought the questions were tedious and very theoretical which made it hard to figure out what you wanted I like homeworks that are more implementation focused However I did enjoy computing the similarity measures by hand It was cool to see 
negative	This homework was challenging in content but not length I sometimes felt lost or unable to debug my spark code I had multiple memory issues with my virtual machine that made it hard for me to complete the homework quickly or to generate output for all parts Piazza posts on the issue went un answered  
neutral	I thought that the first and third problems of this homework were interesting For the first problem it was nice to see how to use custom data types in a MapReduce job For the third problem it was interesting to learn how to obtain the file name and use it in a MapReduce job I did not think the second problem was as interesting however Overall I think this homework was fairly average
neutral	Implementing the pairs map reduce job wasnt overly difficult after doing it on paper in class the major concern that i did not run into in the paper example but that i did run into in the java implementation is how bigrams are formed between two lines if at all I didnt know a good way to address this in my code but maybe map reduce does it for me
neutral	Problems one two and three were good exercises in basic pig data manipulation and the pig development process The only major issue I had was caused by confusion surrounding the inexplicit types in pig I spent many hours trying to figure out why my click through rate calculation was not providing accurate results First I had to learn more about the data set I finally realized I was doing integer division and that was the error 
neutral	I gave this homework a review of 4 stars once again I thought it was a good assignment in the sense that there was a lot of coding and real world problem solving In this sense this homework seemd pretty relevant for realworld applications A problem that I had with the homework is that it wasnt clear whether or not we were supposed to preprocess the data delete duplicate records and you get different answers depending on whether or not you do this Also many of the instructions were a bit unclear
positive	This homework assignment was a good introduction to identifying the qualities and characteristics of big data By doing this homework assignment I got a better understanding of what the aspects of a big data set are that make it unique and potentially hard to deal with It also helped me solve some basic problems regarding and gain some intuition on the appropriate data structures to use when representing the features of a data set in a program 
positive	I think this was a good homework to test basic understanding of big data definitions The examples are applicable and thought provoking The Bonferroni’s Principle question challenged our probability and pattern recognition skills and outlined syntax that may be useful later in the course I didn’t particularly like the reading based question but that is because I learn better from nontext sources
positive	I enjoyed problem 1 and found it incredibly helpful I thought it gave me great experience and lots of examples to consider how the characteristics applied to each big dataset Problem 2 was challenging to get the math correct I thought the article for problem 3 was interesting and relevant Overall this homework assignment took an appropriate amount of time 35 hours in total and I was glad I got to work with a partner I found it beneficial to discuss my opinions with another person 
positive	I thought that this homework was fairly straightforward and a good introductory homework The first part allowed us to better understand big data characteristics and how they exist in some concrete examples The second part allowed us to apply some math from the textbook I thought that the article in the third part was interesting Writing about the databased approach described in the article and its limitations allowed us to better understand the approach
positive	Homework 2 was a good introduction to understanding the way files are stored in the hadoop filesystem I think having us copy and paste the exact commands we used to do the various specified tasks is a good way to have us not only understand how things work under the hood but also to gain some practical experience of executing commands that directly interface with the hadoop file system Also with respect to mapReduce manually computing the process that a MapReduce program uses is a really good way to understand how exactly a mapreduce program works It really isnt that trivial of a process and is different from the way a similar problem would be solved using regular computing
positive	This assignment helped with better visualize the Hadoop distributed file system Question one ensured that my hdfs architecture will be optimized for performance Problems two and three increased my confidence surrounding map reduce concepts It is important for students to fully grasp optimal design of mappers sorters and reducers for successful implementation of map reduce solutions  
positive	My favorite problems were parts 2 and 3 I liked that they gave me practice on manually computing the results of MapReduce It helped me think about how the computer breaks the problem down I enjoyed solving this homework a lot For problem 1 I didnt like having to draw out all of the HDFS storage system I found the question about the metadata confusing 
positive	I thought that this homework was good It really reinforced some ideas that we went over in class such as how a Hadoop Distributed File System works and how MapReduce works In particular I really enjoyed the MapReduce problems as we got to see how it works on a small scale
positive	I worked primarily on problem 2 while my partner did problem 1 I think the concept of skew is cool and incredibly relevant Even something as simple as counting up word frequency or summing up a bunch of 1s can take DRAMATICALLY different time if there are 500 words to sum rather than 3 It was fun to think about how to deal with that problem to reduce the bottleneck I think I understand skew and reduce functions better now as a result of this problem 
positive	I thought that this homework was fairly straightforward Like the previous homeworks it allowed us to reinforce ideas we learned in lab and lecture such as YARN scheduling and MapReduce Additionally we got to explore HDFS outputs in more depth which allows for some practical experience I also thought that skew part was interesting even though we may not have discussed it in class
positive	I give this homework assignment 5 stars Compared to the other assignments this assignment took a much more hands on approach in the sense that it actually made us write some code The problems to be solved were less based in the theory of the mapreduce framework and more based in practical application Overall this assignment was a good introduction to getting your hands dirty in writing mapreduce programs in java
positive	while there were setup challenges for this homework it prepares students to start writing and testing their own map reduce jobs based off required functionality One instruction was ambiguous when it asked for the command for this the hw4pdf file Students will be confused by this instruction I feel more confident after completing this homework 
positive	I thought that this homework was much more challenging than the previous homeworks This is mostly because we had to write custom classes that we have not had much exposure to before However I think that this is valuable as this allows us to tackle more challenging problems than the problems that we have been dealing with thus far
positive	I mainly worked on implementing the inverted index map reduce job This was a good exercise in a new input format and non integer values in key value pairs I ran into difficulty running the job because I was trying to build it from java files when I actually needed to build it out the stubs package 
positive	I liked the problems in homework 5 I had fun thinking about how the partitioner could work to do a global sort and why the output is not by default sorted globally I like that these problems have realworld applications like for this one to be able to quickly and efficienty pull out the oldest or youngest person from a list of names One thing that confused me is why we would want the youngest person by last name and not full name Oh well its ok for me to disagree since thats a pretty easy fix
positive	I gave this homework assignment a rating of 4 stars I thought it was a good introduction to getting us to write a MapReduce job entirely from scratch Also the second part was a good way of getting us to see some statistics as to how our jobs are actually running For example the job looks the same when run with or without a combiner but under the hood the combiner is actually making a large difference as to how efficiently the job is running Overall this was a good homework assignment
positive	I liked implementing a mapreduce job from scratch It was fun to think about what the two separate jobs should do and how taking the output of one job as the input of another can make an overall very good MapReduce program I wish I didnt have the starter code because it confused me more than it helped I got stuck and had to debug a lot with little lines
positive	I thought that this homework was valuable I enjoyed using movie data for the first part as I really enjoy watching movies I also thought the combiner part was informative I understood combiners at a high level going in but now I feel like I understand the details of combiners
positive	I gave homework 7 a 4star rating I thought it was once again a good way to brush up on writing MapReduce jobs from scratch Also it uses the counters introduced in the previous homework to actually give an idea of how efficient our job was Also when analyzing the correlation metrics it was a good step away from programming and into looking into the theory behind how the data from these jobs can be used The reason 1star was deducted is it was a little unclear on how the pseudo code in the RS2 slides corresponds to the Job in part 1 of the assignment 
positive	I thought that this homework was a fun and interesting homework I feel like I understand the cosine similarity algorithms and their variants well after computing the Mapper and Reducer inputs and outputs for the third question The second question also reinforced the advantages and disadvantages between each of the similarity measures
positive	I gave this homework a rating of 4 stars I thought it was a step in the right direction in terms of having the homeworks be more application oriented Since there was a lot of codebased problems we really got our hands dirty and solved realistic problems Also the notion of the tasks in the lab being for madeup companies is a good way to stress how useful the techniquestechnologies we are learning can be in the real world One problem with the lab was that the steps describing the logic of our scripts was vague and a bit unclear 
positive	I thought that this homework was good for reinforcing pig and spark Doing ETL with Spark was interesting for me as I thought it was really cool how we could do the entire process in just a few lines of code Essentially we just needed to import the helper methods from the provided pyspark file create the RDDs and map them to accountnumbermodel strings in one line and then save them to the output directory in another line
positive	I thought this was a good homework in experiencing larger spark jobs I observed that an iterative algorithm like this is not appropriate for MapReduce since we are limited to the map then reduce flow I gave this homework a 4 stars I didnt like that there was no warning about how long the spark job would take to run Mine took around 3 hours 
positive	I liked this homework The question with Pig was hard because I did not know what the cross function was I liked that I got to actually do some cloud computing on real data sets It was frustrating and annoying that the scripts took so long to run so even though I thought I was doing the right thing I might not have been
positive	This homework was interesting as we got to see how PageRank works on a real webgraph with many pages and links It was good to see that our PageRank implementation produced meaningful results in that the UC school websites were the websites with the highest PageRanks This makes sense when thinking about the sheer size of the UC system I believe that the system is the largest employer in the state and the fact that those sites link to each other
